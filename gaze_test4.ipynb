{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 수정 완료본.\n",
    "# 시간 표출 관련 코드 삭제\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# 랜드마크 인덱스 정의\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnP용 3D 모델 포인트\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warning_count, hand_warning_count = 0, 0\n",
    "shoulder_prev_state = \"CENTER\"\n",
    "hand_prev_state = \"NONE\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # 좌우 시선 분석\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # 상하 시선 + 눈 감음 보정 포함\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "\n",
    "        if shoulder_dir != shoulder_prev_state and shoulder_prev_state == \"CENTER\":\n",
    "            shoulder_warning_count += 1\n",
    "        shoulder_prev_state = shoulder_dir\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "        if hand_dir != hand_prev_state and hand_prev_state == \"NONE\":\n",
    "            hand_warning_count += 1\n",
    "        hand_prev_state = hand_dir\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    feedbacks.append((\"Straighten your shoulders.\" if shoulder_dir != \"CENTER\" else \"Shoulders are well aligned.\", (0, 0, 255) if shoulder_dir != \"CENTER\" else (0, 255, 0)))\n",
    "    feedbacks.append((\"Lower your hands naturally.\" if hand_dir == \"VISIBLE\" else \"Hands are properly placed.\", (0, 0, 255) if hand_dir == \"VISIBLE\" else (0, 255, 0)))\n",
    "\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    gaze_score = int((center_frames / total_frames) * 100) if total_frames > 0 else 0\n",
    "    shoulder_score = max(0, 50 - 5 * shoulder_warning_count)\n",
    "    hand_score = max(0, 50 - 5 * hand_warning_count)\n",
    "    total_score = gaze_score + shoulder_score + hand_score - 100\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/100\",\n",
    "        f\"Shoulder Warnings: {shoulder_warning_count} (-{shoulder_warning_count*5})\",\n",
    "        f\"Hand Warnings: {hand_warning_count} (-{hand_warning_count*5})\",\n",
    "        f\"Total Score: {total_score}/100\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a8830d275db2f5d56d95cb53fb469d1ca33211086217bbd3243957b61467a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

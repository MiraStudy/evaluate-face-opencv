{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 시선, 고개, 어깨 / 얼굴, 어깨 이외의 부분 표출시 appearence 표출 - 완성본 \n",
    "# 시선 이탈 / 자세 바른지 피드백 표출\n",
    "\n",
    "# 눈깜빡임 더 조정\n",
    "# 수치 조정함.  -> 일단 완료\n",
    "\n",
    "# 점수 산정 추가코드\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# 랜드마크 인덱스 정의\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnP용 3D 모델 포인트\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames = 0\n",
    "center_frames = 0\n",
    "\n",
    "shoulder_warnings = 0\n",
    "hand_warnings = 0\n",
    "\n",
    "prev_shoulder_state = \"CENTER\"\n",
    "prev_hand_state = \"NONE\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # 좌우 시선 분석\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.46 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.20, avg * 0.85\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -15 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.02 else \"RIGHT UP\" if diff < -0.02 else \"CENTER\"\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- 피드백 메시지 ---\n",
    "    total_frames += 1\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "        if prev_shoulder_state == \"CENTER\":\n",
    "            shoulder_warnings += 1\n",
    "        prev_shoulder_state = shoulder_dir\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "        prev_shoulder_state = \"CENTER\"\n",
    "\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "        if prev_hand_state == \"NONE\":\n",
    "            hand_warnings += 1\n",
    "        prev_hand_state = hand_dir\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "        prev_hand_state = \"NONE\"\n",
    "\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    for i, (k, v) in enumerate(duration.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (10, y + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    # 점수 계산 및 표출\n",
    "    if total_frames > 0:\n",
    "        gaze_score = round((center_frames / total_frames) * 10, 1)\n",
    "        shoulder_score = round(max(0, 10 - 0.2 * shoulder_warnings), 1)\n",
    "        hand_score = round(max(0, 10 - 0.2 * hand_warnings), 1)\n",
    "        \n",
    "        cv2.putText(frame, f\"[Score] Gaze: {gaze_score}/10\", (10, y + 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"[Score] Shoulders: {shoulder_score}/10\", (10, y + 105), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"[Score] Hands: {hand_score}/10\", (10, y + 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 시선, 고개, 어깨 / 얼굴, 어깨 이외의 부분 표출시 appearence 표출 - 완성본 \n",
    "# 시선 이탈 / 자세 바른지 피드백 표출\n",
    "# 점수 산정 추가코드\n",
    "# 눈깜빡임 더 조정함.\n",
    "\n",
    "# 수치 조정함.  -> 어느정도 수정했으나, 조정 더 필요해보임.\n",
    "# -> 카톡의 점수체계 기반으로 다시 작성해야 함. \n",
    "# -> 눈깜박임 이후 넘어가는 시간을 더 오래잡아줘야 함. -> 눈 깜박임으로 아래가 잘 잡히는 거 같음. \n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# 랜드마크 인덱스 정의\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnP용 3D 모델 포인트\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warnings, hand_warnings = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # 좌우 시선 분석\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # 상하 시선 + 눈 감음 보정 포함\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.20, avg * 0.84\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        # 시선 유지 시간\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        # 고개 pitch 추정\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -15 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.02 else \"RIGHT UP\" if diff < -0.02 else \"CENTER\"\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- 피드백 메시지 ---\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "        shoulder_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "        hand_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "\n",
    "    # 텍스트 표출\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    for i, (k, v) in enumerate(duration.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (10, y + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    # 점수 출력\n",
    "    if total_frames > 0:\n",
    "        gaze_score = int((center_frames / total_frames) * 10)\n",
    "    shoulder_score = max(0, 10 - 0.2 * shoulder_warnings)\n",
    "    hand_score = max(0, 10 - 0.2 * hand_warnings)\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/10\",\n",
    "        f\"Shoulder Score: {shoulder_score:.1f}/10\",\n",
    "        f\"Hand Score: {hand_score:.1f}/10\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a8830d275db2f5d56d95cb53fb469d1ca33211086217bbd3243957b61467a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

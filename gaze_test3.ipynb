{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ ÏãúÏÑ†, Í≥†Í∞ú, Ïñ¥Íπ® / ÏñºÍµ¥, Ïñ¥Íπ® Ïù¥Ïô∏Ïùò Î∂ÄÎ∂Ñ ÌëúÏ∂úÏãú appearence ÌëúÏ∂ú - ÏôÑÏÑ±Î≥∏ \n",
    "# ÏãúÏÑ† Ïù¥ÌÉà / ÏûêÏÑ∏ Î∞îÎ•∏ÏßÄ ÌîºÎìúÎ∞± ÌëúÏ∂ú\n",
    "\n",
    "# ÎààÍπúÎπ°ÏûÑ Îçî Ï°∞Ï†ï\n",
    "# ÏàòÏπò Ï°∞Ï†ïÌï®.  -> ÏùºÎã® ÏôÑÎ£å\n",
    "\n",
    "# Ï†êÏàò ÏÇ∞Ï†ï Ï∂îÍ∞ÄÏΩîÎìú\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames = 0\n",
    "center_frames = 0\n",
    "\n",
    "shoulder_warnings = 0\n",
    "hand_warnings = 0\n",
    "\n",
    "prev_shoulder_state = \"CENTER\"\n",
    "prev_hand_state = \"NONE\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ† Î∂ÑÏÑù\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.46 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.20, avg * 0.85\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -15 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.02 else \"RIGHT UP\" if diff < -0.02 else \"CENTER\"\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- ÌîºÎìúÎ∞± Î©îÏãúÏßÄ ---\n",
    "    total_frames += 1\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "        if prev_shoulder_state == \"CENTER\":\n",
    "            shoulder_warnings += 1\n",
    "        prev_shoulder_state = shoulder_dir\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "        prev_shoulder_state = \"CENTER\"\n",
    "\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "        if prev_hand_state == \"NONE\":\n",
    "            hand_warnings += 1\n",
    "        prev_hand_state = hand_dir\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "        prev_hand_state = \"NONE\"\n",
    "\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    for i, (k, v) in enumerate(duration.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (10, y + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    # Ï†êÏàò Í≥ÑÏÇ∞ Î∞è ÌëúÏ∂ú\n",
    "    if total_frames > 0:\n",
    "        gaze_score = round((center_frames / total_frames) * 10, 1)\n",
    "        shoulder_score = round(max(0, 10 - 0.2 * shoulder_warnings), 1)\n",
    "        hand_score = round(max(0, 10 - 0.2 * hand_warnings), 1)\n",
    "        \n",
    "        cv2.putText(frame, f\"[Score] Gaze: {gaze_score}/10\", (10, y + 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"[Score] Shoulders: {shoulder_score}/10\", (10, y + 105), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"[Score] Hands: {hand_score}/10\", (10, y + 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ ÏãúÏÑ†, Í≥†Í∞ú, Ïñ¥Íπ® / ÏñºÍµ¥, Ïñ¥Íπ® Ïù¥Ïô∏Ïùò Î∂ÄÎ∂Ñ ÌëúÏ∂úÏãú appearence ÌëúÏ∂ú - ÏôÑÏÑ±Î≥∏ \n",
    "# ÏãúÏÑ† Ïù¥ÌÉà / ÏûêÏÑ∏ Î∞îÎ•∏ÏßÄ ÌîºÎìúÎ∞± ÌëúÏ∂ú\n",
    "# Ï†êÏàò ÏÇ∞Ï†ï Ï∂îÍ∞ÄÏΩîÎìú\n",
    "# ÎààÍπúÎπ°ÏûÑ Îçî Ï°∞Ï†ïÌï®.\n",
    "\n",
    "# ÏàòÏπò Ï°∞Ï†ïÌï®.  -> Ïñ¥ÎäêÏ†ïÎèÑ ÏàòÏ†ïÌñàÏúºÎÇò, Ï°∞Ï†ï Îçî ÌïÑÏöîÌï¥Î≥¥ÏûÑ.\n",
    "# -> Ïπ¥ÌÜ°Ïùò Ï†êÏàòÏ≤¥Í≥Ñ Í∏∞Î∞òÏúºÎ°ú Îã§Ïãú ÏûëÏÑ±Ìï¥Ïïº Ìï®. \n",
    "# -> ÎààÍπúÎ∞ïÏûÑ Ïù¥ÌõÑ ÎÑòÏñ¥Í∞ÄÎäî ÏãúÍ∞ÑÏùÑ Îçî Ïò§ÎûòÏû°ÏïÑÏ§òÏïº Ìï®. -> Îàà ÍπúÎ∞ïÏûÑÏúºÎ°ú ÏïÑÎûòÍ∞Ä Ïûò Ïû°ÌûàÎäî Í±∞ Í∞ôÏùå. \n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "blink_threshold = 0.016\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warnings, hand_warnings = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ† Î∂ÑÏÑù\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # ÏÉÅÌïò ÏãúÏÑ† + Îàà Í∞êÏùå Î≥¥Ï†ï Ìè¨Ìï®\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        # Í≥†Í∞ú pitch Ï∂îÏ†ï\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- ÌîºÎìúÎ∞± Î©îÏãúÏßÄ ---\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "        shoulder_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "        hand_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "\n",
    "    # ÌÖçÏä§Ìä∏ ÌëúÏ∂ú\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    for i, (k, v) in enumerate(duration.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (10, y + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    # Ï†êÏàò Ï∂úÎ†•\n",
    "    if total_frames > 0:\n",
    "        gaze_score = int((center_frames / total_frames) * 10)\n",
    "    shoulder_score = max(0, 10 - 0.2 * shoulder_warnings)\n",
    "    hand_score = max(0, 10 - 0.2 * hand_warnings)\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/10\",\n",
    "        f\"Shoulder Score: {shoulder_score:.1f}/10\",\n",
    "        f\"Hand Score: {hand_score:.1f}/10\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†êÏàò ÏÇ∞Ï†ïÎ∞©Ïãù ÏàòÏ†ï -> ÌîÑÎ†àÏûÑÎ≥ÑÎ°ú Ï†êÏàòÍ∞Ä ÎßàÏù¥ÎÑàÏä§ Îê®. -> ÏàòÏ†ï ÌïÑÏöî\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© Ïπ¥Î©îÎùº ÌñâÎ†¨\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([[focal_length, 0, center[0]],\n",
    "                     [0, focal_length, center[1]],\n",
    "                     [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),        # Nose tip\n",
    "    (0.0, -63.6, -12.5),    # Chin\n",
    "    (-43.3, 32.7, -26.0),   # Left eye corner\n",
    "    (43.3, 32.7, -26.0),    # Right eye corner\n",
    "    (-28.9, -28.9, -24.1),  # Left mouth\n",
    "    (28.9, -28.9, -24.1)    # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Í¥ÄÎ†® Î≥ÄÏàò\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Îàà ÍπúÎπ°ÏûÑ ÌïÑÌÑ∞ÎßÅ Î≥ÄÏàò\n",
    "blink_threshold = 0.016\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "# Ï†êÏàò Í≥ÑÏÇ∞Ïö© Î≥ÄÏàò\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warnings, hand_warnings = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ†\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # ÏÉÅÌïò ÏãúÏÑ† (Îàà Í∞êÏùå Î¨¥Ïãú)\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        # Í≥†Í∞ú pitch Ï∂îÏ†ï\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- ÌîºÎìúÎ∞± & Í≤ΩÍ≥† Ï≤¥ÌÅ¨ ---\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "        shoulder_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "        hand_warnings += 1\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "\n",
    "    # ---- ÌÖçÏä§Ìä∏ Ï∂úÎ†• ----\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\",\n",
    "                 f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    # Ï†êÏàò Í≥ÑÏÇ∞\n",
    "    if total_frames > 0:\n",
    "        attention_score = int((center_frames / total_frames) * 100)\n",
    "    shoulder_score = max(0, 50 - 5 * shoulder_warnings)\n",
    "    hand_score = max(0, 50 - 5 * hand_warnings)\n",
    "    total_score = max(0, attention_score - 5 * (shoulder_warnings + hand_warnings))\n",
    "\n",
    "    # Ï†êÏàò ÌëúÏãú\n",
    "    for text in [\n",
    "        f\"üéØ Attention Score: {attention_score}%\",\n",
    "        f\"‚ö†Ô∏è Shoulder Warnings: {shoulder_warnings}\",\n",
    "        f\"‚ö†Ô∏è Hand Warnings: {hand_warnings}\",\n",
    "        f\"‚úÖ Shoulder Score: {shoulder_score}/50\",\n",
    "        f\"‚úÖ Hand Score: {hand_score}/50\",\n",
    "        f\"üèÅ Total Score: {total_score}/100\"\n",
    "    ]:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†êÏàò ÏÇ∞Ï†ïÎ∞©Ïãù ÏàòÏ†ï \n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -63.6, -12.5),\n",
    "    (-43.3, 32.7, -26.0),\n",
    "    (43.3, 32.7, -26.0),\n",
    "    (-28.9, -28.9, -24.1),\n",
    "    (28.9, -28.9, -24.1)\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏÉÅÌÉú Î∞è Ï†êÏàò Í¥ÄÎ†® Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "\n",
    "shoulder_warning_state = False\n",
    "hand_warning_state = False\n",
    "shoulder_warning_count = 0\n",
    "hand_warning_count = 0\n",
    "\n",
    "blink_threshold = 0.016\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ† Î∂ÑÏÑù\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # ÏÉÅÌïò ÏãúÏÑ† + Îàà Í∞êÏùå Î≥¥Ï†ï Ìè¨Ìï®\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        # Í≥†Í∞ú pitch Ï∂îÏ†ï\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # --- ÌîºÎìúÎ∞± Î∞è Ï†êÏàò Í≥ÑÏÇ∞ ---\n",
    "    is_centered = (turn_dir == \"CENTER\" and pitch_dir == \"CENTER\" and gaze_h == \"CENTER\" and gaze_v == \"CENTER\")\n",
    "    if is_centered:\n",
    "        center_frames += 1\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "    else:\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "\n",
    "    # Ïñ¥Íπ® Í≤ΩÍ≥† ÏÉÅÌÉú Î≥ÄÌôî Í∞êÏßÄ\n",
    "    if shoulder_dir != \"CENTER\":\n",
    "        if not shoulder_warning_state:\n",
    "            shoulder_warning_count += 1\n",
    "            shoulder_warning_state = True\n",
    "        feedbacks.append((\"Straighten your shoulders.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"Shoulders are well aligned.\", (0, 255, 0)))\n",
    "        shoulder_warning_state = False\n",
    "\n",
    "    # ÏÜê Í≤ΩÍ≥† ÏÉÅÌÉú Î≥ÄÌôî Í∞êÏßÄ\n",
    "    if hand_dir == \"VISIBLE\":\n",
    "        if not hand_warning_state:\n",
    "            hand_warning_count += 1\n",
    "            hand_warning_state = True\n",
    "        feedbacks.append((\"Lower your hands naturally.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"Hands are properly placed.\", (0, 255, 0)))\n",
    "        hand_warning_state = False\n",
    "\n",
    "    # ÌÖçÏä§Ìä∏ Ï∂úÎ†•\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    for i, (k, v) in enumerate(duration.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (10, y + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    # Ï†êÏàò Í≥ÑÏÇ∞\n",
    "    gaze_score = int((center_frames / total_frames) * 100) if total_frames > 0 else 0\n",
    "    shoulder_score = max(0, 50 - 5 * shoulder_warning_count)\n",
    "    hand_score = max(0, 50 - 5 * hand_warning_count)\n",
    "    total_score = gaze_score + shoulder_score + hand_score\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/100\",\n",
    "        f\"Shoulder Score: {shoulder_score}/50 (Warnings: {shoulder_warning_count})\",\n",
    "        f\"Hand Score: {hand_score}/50 (Warnings: {hand_warning_count})\",\n",
    "        f\"Total Score: {total_score}/200\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†êÏàò ÏÇ∞Ï†ï Î∞©Ïãù ÏàòÏ†ï -> total scoreÎ•º 100Ï†êÏúºÎ°ú\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "state = None\n",
    "state_start = time.time()\n",
    "duration = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "blink_threshold = 0.018\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warning_count, hand_warning_count = 0, 0\n",
    "shoulder_prev_state = \"CENTER\"\n",
    "hand_prev_state = \"NONE\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ† Î∂ÑÏÑù\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # ÏÉÅÌïò ÏãúÏÑ† + Îàà Í∞êÏùå Î≥¥Ï†ï Ìè¨Ìï®\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = state if state else \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        now = time.time()\n",
    "        if gaze_v != state:\n",
    "            if state:\n",
    "                duration[state] += now - state_start\n",
    "            state_start, state = now, gaze_v\n",
    "\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "\n",
    "        if shoulder_dir != shoulder_prev_state and shoulder_prev_state == \"CENTER\":\n",
    "            shoulder_warning_count += 1\n",
    "        shoulder_prev_state = shoulder_dir\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "        if hand_dir != hand_prev_state and hand_prev_state == \"NONE\":\n",
    "            hand_warning_count += 1\n",
    "        hand_prev_state = hand_dir\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    feedbacks.append((\"Straighten your shoulders.\" if shoulder_dir != \"CENTER\" else \"Shoulders are well aligned.\", (0, 0, 255) if shoulder_dir != \"CENTER\" else (0, 255, 0)))\n",
    "    feedbacks.append((\"Lower your hands naturally.\" if hand_dir == \"VISIBLE\" else \"Hands are properly placed.\", (0, 0, 255) if hand_dir == \"VISIBLE\" else (0, 255, 0)))\n",
    "\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    gaze_score = int((center_frames / total_frames) * 100) if total_frames > 0 else 0\n",
    "    shoulder_score = max(0, 50 - 5 * shoulder_warning_count)\n",
    "    hand_score = max(0, 50 - 5 * hand_warning_count)\n",
    "    total_score = gaze_score + shoulder_score + hand_score - 100\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/100\",\n",
    "        f\"Shoulder Warnings: {shoulder_warning_count} (-{shoulder_warning_count*5})\",\n",
    "        f\"Hand Warnings: {hand_warning_count} (-{hand_warning_count*5})\",\n",
    "        f\"Total Score: {total_score}/100\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if state:\n",
    "    duration[state] += time.time() - state_start\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ ÏàòÏ†ï ÏôÑÎ£åÎ≥∏.\n",
    "# ÏãúÍ∞Ñ ÌëúÏ∂ú Í¥ÄÎ†® ÏΩîÎìú ÏÇ≠Ï†ú\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§ Ï†ïÏùò\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "LEFT_INDEX = mp_pose.PoseLandmark.LEFT_INDEX\n",
    "RIGHT_ELBOW = mp_pose.PoseLandmark.RIGHT_ELBOW\n",
    "\n",
    "# solvePnPÏö© 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),       # Nose tip\n",
    "    (0.0, -63.6, -12.5),   # Chin\n",
    "    (-43.3, 32.7, -26.0),  # Left eye corner\n",
    "    (43.3, 32.7, -26.0),   # Right eye corner\n",
    "    (-28.9, -28.9, -24.1), # Left mouth\n",
    "    (28.9, -28.9, -24.1)   # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown = 5\n",
    "blink_counter = 0\n",
    "calibration_vals, is_calibrated = [], False\n",
    "up_thresh, down_thresh = 0.0, 1.0\n",
    "\n",
    "total_frames, center_frames = 0, 0\n",
    "shoulder_warning_count, hand_warning_count = 0, 0\n",
    "shoulder_prev_state = \"CENTER\"\n",
    "hand_prev_state = \"NONE\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_dir, pitch_dir, turn_dir, shoulder_dir, hand_dir = \"\", \"\", \"\", \"\", \"\"\n",
    "    feedbacks = []\n",
    "\n",
    "    total_frames += 1\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        lm = face_result.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Ï¢åÏö∞ ÏãúÏÑ† Î∂ÑÏÑù\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / (np.linalg.norm(left_iris_right - left_iris_left) + 1e-6)\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / (np.linalg.norm(right_iris_right - right_iris_left) + 1e-6)\n",
    "\n",
    "        gaze_h = \"LEFT\" if left_ratio < 0.45 else \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "\n",
    "        # ÏÉÅÌïò ÏãúÏÑ† + Îàà Í∞êÏùå Î≥¥Ï†ï Ìè¨Ìï®\n",
    "        eye_top, eye_bot = lm[159].y, lm[145].y\n",
    "        opening = abs(eye_top - eye_bot)\n",
    "        if opening < blink_threshold:\n",
    "            blink_counter = blink_cooldown\n",
    "            gaze_v = \"CENTER\"\n",
    "        elif blink_counter > 0:\n",
    "            blink_counter -= 1\n",
    "            gaze_v = \"CENTER\"\n",
    "        else:\n",
    "            if not is_calibrated:\n",
    "                calibration_vals.append(opening)\n",
    "                if len(calibration_vals) == 30:\n",
    "                    avg = np.mean(calibration_vals)\n",
    "                    up_thresh, down_thresh = avg * 1.10, avg * 0.88\n",
    "                    is_calibrated = True\n",
    "                gaze_v = \"CENTER\"\n",
    "            else:\n",
    "                gaze_v = \"UP\" if opening > up_thresh else \"DOWN\" if opening < down_thresh else \"CENTER\"\n",
    "\n",
    "        image_points = np.array([[lm[i].x * w, lm[i].y * h] for i in [1,152,33,263,78,308]], dtype=np.float32)\n",
    "        cam_mtx = get_camera_matrix(w, h)\n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, cam_mtx, np.zeros((4,1)))\n",
    "        pitch_dir = \"CENTER\"\n",
    "        if success:\n",
    "            rmat, _ = cv2.Rodrigues(rvec)\n",
    "            pitch = np.degrees(np.arcsin(-rmat[2][1]))\n",
    "            pitch_dir = \"UP\" if pitch < -14 else \"DOWN\" if pitch > 9 else \"CENTER\"\n",
    "\n",
    "    if pose_result.pose_landmarks:\n",
    "        plm = pose_result.pose_landmarks.landmark\n",
    "        le, re = lm[LEFT_EYE_CENTER], lm[RIGHT_EYE_CENTER]\n",
    "        le2e = abs(le.x - plm[LEFT_EAR].x)\n",
    "        re2e = abs(re.x - plm[RIGHT_EAR].x)\n",
    "        turn_dir = \"LEFT\" if le2e > re2e + 0.035 else \"RIGHT\" if re2e > le2e + 0.035 else \"CENTER\"\n",
    "\n",
    "        diff = plm[LEFT_SHOULDER].y - plm[RIGHT_SHOULDER].y\n",
    "        shoulder_dir = \"LEFT UP\" if diff > 0.03 else \"RIGHT UP\" if diff < -0.03 else \"CENTER\"\n",
    "\n",
    "        if shoulder_dir != shoulder_prev_state and shoulder_prev_state == \"CENTER\":\n",
    "            shoulder_warning_count += 1\n",
    "        shoulder_prev_state = shoulder_dir\n",
    "\n",
    "        hand_dir = \"VISIBLE\" if plm[LEFT_INDEX].visibility > 0.5 or plm[RIGHT_ELBOW].visibility > 0.5 else \"NONE\"\n",
    "        if hand_dir != hand_prev_state and hand_prev_state == \"NONE\":\n",
    "            hand_warning_count += 1\n",
    "        hand_prev_state = hand_dir\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    if turn_dir != \"CENTER\" or pitch_dir != \"CENTER\" or gaze_h != \"CENTER\" or gaze_v != \"CENTER\":\n",
    "        feedbacks.append((\"Look at the center.\", (0, 0, 255)))\n",
    "    else:\n",
    "        feedbacks.append((\"You're looking straight ahead.\", (0, 255, 0)))\n",
    "        center_frames += 1\n",
    "\n",
    "    feedbacks.append((\"Straighten your shoulders.\" if shoulder_dir != \"CENTER\" else \"Shoulders are well aligned.\", (0, 0, 255) if shoulder_dir != \"CENTER\" else (0, 255, 0)))\n",
    "    feedbacks.append((\"Lower your hands naturally.\" if hand_dir == \"VISIBLE\" else \"Hands are properly placed.\", (0, 0, 255) if hand_dir == \"VISIBLE\" else (0, 255, 0)))\n",
    "\n",
    "    y = 30\n",
    "    for text in [f\"Gaze: {gaze_h} / {gaze_v}\", f\"Head: {turn_dir}\", f\"Pitch: {pitch_dir}\", f\"Shoulders: {shoulder_dir}\", f\"Hands: {hand_dir}\"]:\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "        y += 25\n",
    "\n",
    "    for fb, color in feedbacks:\n",
    "        cv2.putText(frame, fb, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        y += 30\n",
    "\n",
    "    gaze_score = int((center_frames / total_frames) * 100) if total_frames > 0 else 0\n",
    "    shoulder_score = max(0, 50 - 5 * shoulder_warning_count)\n",
    "    hand_score = max(0, 50 - 5 * hand_warning_count)\n",
    "    total_score = gaze_score + shoulder_score + hand_score - 100\n",
    "\n",
    "    score_texts = [\n",
    "        f\"Gaze Score: {gaze_score}/100\",\n",
    "        f\"Shoulder Warnings: {shoulder_warning_count} (-{shoulder_warning_count*5})\",\n",
    "        f\"Hand Warnings: {hand_warning_count} (-{hand_warning_count*5})\",\n",
    "        f\"Total Score: {total_score}/100\"\n",
    "    ]\n",
    "    for text in score_texts:\n",
    "        y += 30\n",
    "        cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Head Shoulder Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a8830d275db2f5d56d95cb53fb469d1ca33211086217bbd3243957b61467a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fe3d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• FaceMesh started - ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# Ï¢åÏö∞ / ÏãúÏÑ†(face_mesh) Ï∏°Ï†ï\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• FaceMesh started - ESC to exit\")\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "RIGHT_EYE_OUTER = 263\n",
    "LEFT_IRIS_LEFT = 471\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    gaze_text = \"\"\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        face = result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # Ï¢åÌëú Ï∂îÏ∂ú (ÌîΩÏÖÄ Îã®ÏúÑ)\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "\n",
    "        # Í±∞Î¶¨ Í≥ÑÏÇ∞\n",
    "        left_distance = np.linalg.norm(left_eye_outer - left_iris_left)\n",
    "        right_distance = np.linalg.norm(right_eye_outer - right_iris_right)\n",
    "\n",
    "        # ÏãúÏÑ† ÌåêÎ≥Ñ Í∏∞Ï§Ä\n",
    "        if left_distance < 10:\n",
    "            gaze_text = \"üëÅÔ∏è Looking LEFT\"\n",
    "        elif right_distance < 10:\n",
    "            gaze_text = \"üëÅÔ∏è Looking RIGHT\"\n",
    "        else:\n",
    "            gaze_text = \"üëÅÔ∏è Looking CENTER\"\n",
    "\n",
    "        # ÎîîÎ≤ÑÍπÖÏö© Ï†ê ÏãúÍ∞ÅÌôî\n",
    "        for idx in [LEFT_EYE_OUTER, LEFT_IRIS_LEFT, RIGHT_EYE_OUTER, RIGHT_IRIS_RIGHT]:\n",
    "            cx = int(lm[idx].x * w)\n",
    "            cy = int(lm[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 255, 255), -1)\n",
    "\n",
    "    # Ï∂úÎ†• ÌÖçÏä§Ìä∏\n",
    "    cv2.putText(frame, gaze_text, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Iris Gaze Tracking (Outer Iris Landmarks)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0c73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Tracking started - ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# Ï¢åÏö∞ / ÏãúÏÑ†(face_mesh), Í≥†Í∞ú(face_mesh), Ïñ¥Íπ®(Pose) Ï∏°Ï†ï \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Tracking started - ESC to exit\")\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "RIGHT_EYE_OUTER = 263\n",
    "LEFT_IRIS_LEFT = 471\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "LEFT_EAR = 234\n",
    "RIGHT_EAR = 454\n",
    "LEFT_EYE_CENTER = 468\n",
    "RIGHT_EYE_CENTER = 473\n",
    "\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_text, head_text, shoulder_text = \"\", \"\", \"\"\n",
    "\n",
    "    # ---------- 1. ÏñºÍµ¥ Î∞©Ìñ•, ÏãúÏÑ† ----------\n",
    "    if face_result.multi_face_landmarks:\n",
    "        face = face_result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # ÏãúÏÑ† Î∞©Ìñ•\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "\n",
    "        left_dist = np.linalg.norm(left_eye_outer - left_iris)\n",
    "        right_dist = np.linalg.norm(right_eye_outer - right_iris)\n",
    "\n",
    "        if left_dist < 10:\n",
    "            gaze_text = \"üëÅÔ∏è Gaze: LEFT\"\n",
    "        elif right_dist < 10:\n",
    "            gaze_text = \"üëÅÔ∏è Gaze: RIGHT\"\n",
    "        else:\n",
    "            gaze_text = \"üëÅÔ∏è Gaze: CENTER\"\n",
    "\n",
    "        # Í≥†Í∞ú Î∞©Ìñ• (Ïñë Îàà ‚Üî Í∑Ä Í±∞Î¶¨ ÎπÑÍµê)\n",
    "        left_eye_center = lm[LEFT_EYE_CENTER]\n",
    "        right_eye_center = lm[RIGHT_EYE_CENTER]\n",
    "        left_ear = lm[LEFT_EAR]\n",
    "        right_ear = lm[RIGHT_EAR]\n",
    "\n",
    "        left_eye_to_ear = abs(left_eye_center.x - left_ear.x)\n",
    "        right_eye_to_ear = abs(right_eye_center.x - right_ear.x)\n",
    "\n",
    "        if left_eye_to_ear > right_eye_to_ear + 0.02:\n",
    "            head_text = \"üß† Head: RIGHT TURN\"\n",
    "        elif right_eye_to_ear > left_eye_to_ear + 0.02:\n",
    "            head_text = \"üß† Head: LEFT TURN\"\n",
    "        else:\n",
    "            head_text = \"üß† Head: CENTER\"\n",
    "\n",
    "        # Îàà/ÌôçÏ±Ñ ÏãúÍ∞ÅÌôî\n",
    "        for idx in [LEFT_EYE_OUTER, LEFT_IRIS_LEFT, RIGHT_EYE_OUTER, RIGHT_IRIS_RIGHT]:\n",
    "            cx, cy = int(lm[idx].x * w), int(lm[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 255, 255), -1)\n",
    "\n",
    "    # ---------- 2. Ïñ¥Íπ® ÏûêÏÑ∏ ----------\n",
    "    if pose_result.pose_landmarks:\n",
    "        landmarks = pose_result.pose_landmarks.landmark\n",
    "        left_y = landmarks[LEFT_SHOULDER].y\n",
    "        right_y = landmarks[RIGHT_SHOULDER].y\n",
    "        diff = left_y - right_y\n",
    "\n",
    "        if diff > 0.018:\n",
    "            shoulder_text = \"üßç Shoulder: LEFT UP\"\n",
    "        elif diff < -0.018:\n",
    "            shoulder_text = \"üßç Shoulder: RIGHT UP\"\n",
    "        else:\n",
    "            shoulder_text = \"üßç Shoulder: STRAIGHT\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_result.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=3)\n",
    "        )\n",
    "\n",
    "    # ---------- Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ Ï∂úÎ†• ----------\n",
    "    y0 = 30\n",
    "    for line in [gaze_text, head_text, shoulder_text]:\n",
    "        if line:\n",
    "            cv2.putText(frame, line, (10, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            y0 += 30\n",
    "\n",
    "    cv2.imshow(\"Full Tracker (Gaze + Head + Shoulder)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41615642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Gaze ratio tracking started - ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# ÏãúÏÑ† Ï∏°Ï†ïÌï†Îïå, Îí§Î°úÍ∞ÄÎ©¥ ÏàòÏπòÍ∞Ä ÏûëÏïÑÏßÄÎãàÍπå Ï≤òÏùå ifÏù∏ ÏôºÏ™ΩÏù¥ Í≥ÑÏÜç Îñ†ÏÑú, ÎààÎèôÏûê Í∏∏Ïù¥ ÏÉùÍ∞ÅÌï¥ÏÑú Îàà ÏôºÏ™ΩÍ≥º ÏñºÎßàÎÇò Í∞ÄÍπåÏö¥ÏßÄ ÏòÜÏóê Îî∞Îäî Î∞©ÏãùÏúºÎ°ú Ìï¥Î¥Ñ.\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Gaze ratio tracking started - ESC to exit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    gaze_text = \"\"\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        face = result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # ÌîΩÏÖÄ Ï¢åÌëú Ï∂îÏ∂ú\n",
    "        eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "\n",
    "        iris_width = np.linalg.norm(iris_right - iris_left) + 1e-6  # ÎÇòÎàóÏÖà Ïò§Î•ò Î∞©ÏßÄ\n",
    "        to_outer = np.linalg.norm(iris_left - eye_outer)\n",
    "\n",
    "        ratio = to_outer / iris_width\n",
    "\n",
    "        # ÏûÑÍ≥ÑÍ∞í Í∏∞Ï§Ä (0.48 Ïù¥ÌïòÎ©¥ ÏôºÏ™Ω ÏùëÏãúÎ°ú ÌåêÎã®)\n",
    "        if ratio < 0.48:\n",
    "            gaze_text = f\"üëÅÔ∏è LEFT EYE ‚Üí Looking LEFT ({ratio:.2f})\"\n",
    "        else:\n",
    "            gaze_text = f\"üëÅÔ∏è LEFT EYE ‚Üí CENTER/RIGHT ({ratio:.2f})\"\n",
    "\n",
    "        # ÎîîÎ≤ÑÍπÖÏö© Ï†ê Ï∂úÎ†•\n",
    "        for idx in [LEFT_EYE_OUTER, LEFT_IRIS_LEFT, LEFT_IRIS_RIGHT]:\n",
    "            cx, cy = int(lm[idx].x * w), int(lm[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 255, 255), -1)\n",
    "\n",
    "    # ÌÖçÏä§Ìä∏ Ï∂úÎ†•\n",
    "    cv2.putText(frame, gaze_text, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze Ratio (Left Eye)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062233c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Tracking started - ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# ÏãúÏÑ†, Í≥†Í∞ú, Ïñ¥Íπ® Î∂ÑÏÑù (ÏãúÏÑ† ÎπÑÏú®Î°ú Ìï¥ÏÑú)Ìï©Ï≥§ÎäîÎç∞, Í≥†Í∞úÍ∞Ä Ïûò ÏïàÎêå -> ÌôïÏù∏Ìï¥ÏïºÌï®. \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Tracking started - ESC to exit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # ÏãúÏÑ† Î∂ÑÏÑù\n",
    "    gaze_text = \"\"\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    if face_result.multi_face_landmarks:\n",
    "        face = face_result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # ÏôºÏ™Ω Îàà\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_iris_width = np.linalg.norm(left_iris_right - left_iris_left) + 1e-6\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / left_iris_width\n",
    "\n",
    "        # Ïò§Î•∏Ï™Ω Îàà\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_iris_width = np.linalg.norm(right_iris_right - right_iris_left) + 1e-6\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / right_iris_width\n",
    "\n",
    "        # ÏãúÏÑ† Î∞©Ìñ• Í≤∞Ï†ï\n",
    "        left_gaze = \"LEFT\" if left_ratio < 0.48 else \"CENTER\"\n",
    "        right_gaze = \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "        result_gaze = \"LEFT\" if left_gaze == \"LEFT\" else \"RIGHT\" if right_gaze == \"RIGHT\" else \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"L-Gaze:{left_gaze}({left_ratio:.2f})|R-Gaze:{right_gaze}({right_ratio:.2f})‚Üí{result_gaze}\"\n",
    "\n",
    "        # ÎîîÎ≤ÑÍπÖÏö© Îàà Ï£ºÎ≥Ä Ï†ê\n",
    "        for idx in [LEFT_EYE_OUTER, LEFT_IRIS_LEFT, LEFT_IRIS_RIGHT,\n",
    "                    RIGHT_EYE_OUTER, RIGHT_IRIS_LEFT, RIGHT_IRIS_RIGHT]:\n",
    "            cx, cy = int(lm[idx].x * w), int(lm[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 255, 255), -1)\n",
    "\n",
    "    # Ìè¨Ï¶à Î∂ÑÏÑù\n",
    "    pose_result = pose.process(rgb)\n",
    "    pose_text = \"\"\n",
    "    if pose_result.pose_landmarks:\n",
    "        landmarks = pose_result.pose_landmarks.landmark\n",
    "\n",
    "        # Í≥†Í∞ú Î∞©Ìñ• (Ï¢åÏö∞ Í∑Ä Í∏∞Ï§Ä)\n",
    "        left_ear_x = landmarks[mp_pose.PoseLandmark.LEFT_EAR].x\n",
    "        right_ear_x = landmarks[mp_pose.PoseLandmark.RIGHT_EAR].x\n",
    "        head_text = \"\"\n",
    "        if left_ear_x - right_ear_x > 0.08:\n",
    "            head_text = \"HEAD ‚Üí LEFT\"\n",
    "        elif right_ear_x - left_ear_x > 0.08:\n",
    "            head_text = \"HEAD ‚Üí RIGHT\"\n",
    "        else:\n",
    "            head_text = \"HEAD ‚Üí CENTER\"\n",
    "\n",
    "        # Ïñ¥Íπ® ÎÜíÏù¥ ÎπÑÍµê\n",
    "        left_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y\n",
    "        right_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y\n",
    "        diff = left_shoulder_y - right_shoulder_y\n",
    "        if diff > 0.012:\n",
    "            shoulder_text = \"LEFT SHOULDER UP\"\n",
    "        elif diff < -0.012:\n",
    "            shoulder_text = \"RIGHT SHOULDER UP\"\n",
    "        else:\n",
    "            shoulder_text = \"SHOULDERS STRAIGHT\"\n",
    "\n",
    "        pose_text = f\"{head_text} | üßç {shoulder_text}\"\n",
    "\n",
    "        # Ìè¨Ï¶à ÎûúÎìúÎßàÌÅ¨ Í∑∏Î¶¨Í∏∞\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_result.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    # Í≤∞Í≥º ÌÖçÏä§Ìä∏ Ï∂úÎ†•\n",
    "    y = 30\n",
    "    for line in [gaze_text, pose_text]:\n",
    "        if line:\n",
    "            cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            y += 30\n",
    "\n",
    "    cv2.imshow(\"Full Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67cff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Gaze + Head + Shoulder Tracking Started - ESC to exit\n"
     ]
    }
   ],
   "source": [
    "# Ï¢åÏö∞ ÏãúÏÑ†, Í≥†Í∞ú, Ïñ¥Íπ® ÏôÑÏÑ±\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# FaceMesh & Pose ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_EYE_CENTER = 468\n",
    "\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_EYE_CENTER = 473\n",
    "\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "\n",
    "# ÏõπÏ∫† ÏãúÏûë\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Gaze + Head + Shoulder Tracking Started - ESC to exit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # FaceMesh ÏãúÏÑ† Î∂ÑÏÑù\n",
    "    gaze_text = \"\"\n",
    "    head_text = \"\"\n",
    "    face_result = face_mesh.process(rgb)\n",
    "\n",
    "    # Pose Î∂ÑÏÑù\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        face = face_result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # === ÏôºÏ™Ω Îàà ÏãúÏÑ† Î∂ÑÏÑù ===\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_iris_width = np.linalg.norm(left_iris_right - left_iris_left) + 1e-6\n",
    "        left_ratio = np.linalg.norm(left_iris_left - left_eye_outer) / left_iris_width\n",
    "\n",
    "        # === Ïò§Î•∏Ï™Ω Îàà ÏãúÏÑ† Î∂ÑÏÑù ===\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_iris_width = np.linalg.norm(right_iris_right - right_iris_left) + 1e-6\n",
    "        right_ratio = np.linalg.norm(right_eye_outer - right_iris_right) / right_iris_width\n",
    "\n",
    "        # ÏãúÏÑ† Î∞©Ìñ• Í≤∞Ï†ï\n",
    "        left_gaze = \"LEFT\" if left_ratio < 0.48 else \"CENTER\"\n",
    "        right_gaze = \"RIGHT\" if right_ratio < 0.48 else \"CENTER\"\n",
    "        result_gaze = \"LEFT\" if left_gaze == \"LEFT\" else \"RIGHT\" if right_gaze == \"RIGHT\" else \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"L-Gaze:{left_gaze}({left_ratio:.2f})|R-Gaze:{right_gaze}({right_ratio:.2f})‚Üí{result_gaze}\"\n",
    "\n",
    "        # === Í≥†Í∞ú Î∞©Ìñ•: Ïñë Îàà ‚Üî Í∑Ä Í±∞Î¶¨ ÎπÑÍµê ===\n",
    "        if pose_result.pose_landmarks:\n",
    "            pose_lm = pose_result.pose_landmarks.landmark\n",
    "\n",
    "            left_eye_center = lm[LEFT_EYE_CENTER]\n",
    "            right_eye_center = lm[RIGHT_EYE_CENTER]\n",
    "            left_ear = pose_lm[LEFT_EAR]\n",
    "            right_ear = pose_lm[RIGHT_EAR]\n",
    "\n",
    "            left_eye_to_ear = abs(left_eye_center.x - left_ear.x)\n",
    "            right_eye_to_ear = abs(right_eye_center.x - right_ear.x)\n",
    "\n",
    "            if left_eye_to_ear > right_eye_to_ear + 0.03:\n",
    "                head_text = \"Head: LEFT TURN\"\n",
    "            elif right_eye_to_ear > left_eye_to_ear + 0.03:\n",
    "                head_text = \"Head: RIGHT TURN\"\n",
    "            else:\n",
    "                head_text = \"Head: CENTER\"\n",
    "\n",
    "        # ÎîîÎ≤ÑÍπÖÏö© Îàà/ÌôçÏ±Ñ Ï†ê\n",
    "        for idx in [LEFT_EYE_OUTER, LEFT_IRIS_LEFT, LEFT_IRIS_RIGHT,\n",
    "                    RIGHT_EYE_OUTER, RIGHT_IRIS_LEFT, RIGHT_IRIS_RIGHT]:\n",
    "            cx, cy = int(lm[idx].x * w), int(lm[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 255, 255), -1)\n",
    "\n",
    "    # === Ïñ¥Íπ® ÏûêÏÑ∏ ===\n",
    "    shoulder_text = \"\"\n",
    "    if pose_result.pose_landmarks:\n",
    "        lm = pose_result.pose_landmarks.landmark\n",
    "        left_shoulder_y = lm[LEFT_SHOULDER].y\n",
    "        right_shoulder_y = lm[RIGHT_SHOULDER].y\n",
    "        diff = left_shoulder_y - right_shoulder_y\n",
    "\n",
    "        if diff > 0.012:\n",
    "            shoulder_text = \"LEFT SHOULDER UP\"\n",
    "        elif diff < -0.012:\n",
    "            shoulder_text = \"RIGHT SHOULDER UP\"\n",
    "        else:\n",
    "            shoulder_text = \"SHOULDERS STRAIGHT\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_result.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    # ÌÖçÏä§Ìä∏ Ï∂úÎ†•\n",
    "    y = 30\n",
    "    for text in [gaze_text, head_text, shoulder_text]:\n",
    "        if text:\n",
    "            cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            y += 30\n",
    "\n",
    "    cv2.imshow(\"Full Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93af7bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Tracking Started - ESC to exit\n",
      "üëÅÔ∏è Ïù¥Ï†Ñ ÏãúÏÑ† 'NONE' Ïú†ÏßÄ ÏãúÍ∞Ñ: 0.33s\n"
     ]
    }
   ],
   "source": [
    "# Ï¢åÏö∞ ÏôÑÏÑ± + ÏúÑ, ÏïÑÎûò Ï∂îÍ∞Ä\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# ÎûúÎìúÎßàÌÅ¨ Ïù∏Îç±Ïä§\n",
    "LEFT_EYE_OUTER = 33\n",
    "LEFT_IRIS_LEFT = 471\n",
    "LEFT_IRIS_RIGHT = 469\n",
    "LEFT_IRIS_TOP = 470\n",
    "LEFT_IRIS_BOTTOM = 472\n",
    "LEFT_EYE_CENTER = 468\n",
    "\n",
    "RIGHT_EYE_OUTER = 263\n",
    "RIGHT_IRIS_LEFT = 476\n",
    "RIGHT_IRIS_RIGHT = 474\n",
    "RIGHT_IRIS_TOP = 475\n",
    "RIGHT_IRIS_BOTTOM = 477\n",
    "RIGHT_EYE_CENTER = 473\n",
    "\n",
    "LEFT_EAR = mp_pose.PoseLandmark.LEFT_EAR\n",
    "RIGHT_EAR = mp_pose.PoseLandmark.RIGHT_EAR\n",
    "LEFT_SHOULDER = mp_pose.PoseLandmark.LEFT_SHOULDER\n",
    "RIGHT_SHOULDER = mp_pose.PoseLandmark.RIGHT_SHOULDER\n",
    "\n",
    "# ÏõπÏ∫†\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Webcam not opened.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üé• Tracking Started - ESC to exit\")\n",
    "\n",
    "prev_time = time.time()\n",
    "prev_gaze = \"NONE\"\n",
    "gaze_start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    pose_result = pose.process(rgb)\n",
    "\n",
    "    gaze_text = \"\"\n",
    "    head_text = \"\"\n",
    "    shoulder_text = \"\"\n",
    "    gaze_direction = \"\"\n",
    "\n",
    "    if face_result.multi_face_landmarks:\n",
    "        face = face_result.multi_face_landmarks[0]\n",
    "        lm = face.landmark\n",
    "\n",
    "        # === ÏôºÏ™Ω Îàà (Ï¢åÏö∞/ÏÉÅÌïò) ===\n",
    "        left_eye_outer = np.array([lm[LEFT_EYE_OUTER].x * w, lm[LEFT_EYE_OUTER].y * h])\n",
    "        left_iris_left = np.array([lm[LEFT_IRIS_LEFT].x * w, lm[LEFT_IRIS_LEFT].y * h])\n",
    "        left_iris_right = np.array([lm[LEFT_IRIS_RIGHT].x * w, lm[LEFT_IRIS_RIGHT].y * h])\n",
    "        left_iris_top = np.array([lm[LEFT_IRIS_TOP].x * w, lm[LEFT_IRIS_TOP].y * h])\n",
    "        left_iris_bottom = np.array([lm[LEFT_IRIS_BOTTOM].x * w, lm[LEFT_IRIS_BOTTOM].y * h])\n",
    "\n",
    "        left_iris_width = np.linalg.norm(left_iris_right - left_iris_left) + 1e-6\n",
    "        left_iris_height = np.linalg.norm(left_iris_top - left_iris_bottom) + 1e-6\n",
    "\n",
    "        left_ratio_h = np.linalg.norm(left_iris_left - left_eye_outer) / left_iris_width\n",
    "        left_ratio_v = np.linalg.norm(left_iris_top - left_iris_bottom) / left_iris_height\n",
    "\n",
    "        # === Ïò§Î•∏Ï™Ω Îàà (Ï¢åÏö∞/ÏÉÅÌïò) ===\n",
    "        right_eye_outer = np.array([lm[RIGHT_EYE_OUTER].x * w, lm[RIGHT_EYE_OUTER].y * h])\n",
    "        right_iris_left = np.array([lm[RIGHT_IRIS_LEFT].x * w, lm[RIGHT_IRIS_LEFT].y * h])\n",
    "        right_iris_right = np.array([lm[RIGHT_IRIS_RIGHT].x * w, lm[RIGHT_IRIS_RIGHT].y * h])\n",
    "        right_iris_top = np.array([lm[RIGHT_IRIS_TOP].x * w, lm[RIGHT_IRIS_TOP].y * h])\n",
    "        right_iris_bottom = np.array([lm[RIGHT_IRIS_BOTTOM].x * w, lm[RIGHT_IRIS_BOTTOM].y * h])\n",
    "\n",
    "        right_iris_width = np.linalg.norm(right_iris_right - right_iris_left) + 1e-6\n",
    "        right_iris_height = np.linalg.norm(right_iris_top - right_iris_bottom) + 1e-6\n",
    "\n",
    "        right_ratio_h = np.linalg.norm(right_iris_right - right_eye_outer) / right_iris_width\n",
    "        right_ratio_v = np.linalg.norm(right_iris_top - right_iris_bottom) / right_iris_height\n",
    "\n",
    "        # ÏãúÏÑ† Î∞©Ìñ• Í≤∞Ï†ï\n",
    "        gaze_h = \"LEFT\" if left_ratio_h < 0.48 else \"RIGHT\" if right_ratio_h < 0.48 else \"CENTER\"\n",
    "        gaze_v = \"UP\" if left_ratio_v > 0.55 else \"DOWN\" if left_ratio_v < 0.45 else \"CENTER\"\n",
    "        gaze_direction = f\"{gaze_h} / {gaze_v}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Í≥ÑÏÇ∞\n",
    "        now = time.time()\n",
    "        if gaze_direction != prev_gaze:\n",
    "            duration = now - gaze_start_time\n",
    "            print(f\"üëÅÔ∏è Ïù¥Ï†Ñ ÏãúÏÑ† '{prev_gaze}' Ïú†ÏßÄ ÏãúÍ∞Ñ: {duration:.2f}s\")\n",
    "            gaze_start_time = now\n",
    "            prev_gaze = gaze_direction\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # === Í≥†Í∞ú Î∞©Ìñ• ===\n",
    "        if pose_result.pose_landmarks:\n",
    "            pose_lm = pose_result.pose_landmarks.landmark\n",
    "            left_eye_center = lm[LEFT_EYE_CENTER]\n",
    "            right_eye_center = lm[RIGHT_EYE_CENTER]\n",
    "            left_ear = pose_lm[LEFT_EAR]\n",
    "            right_ear = pose_lm[RIGHT_EAR]\n",
    "\n",
    "            # Ï¢åÏö∞\n",
    "            left_eye_to_ear = abs(left_eye_center.x - left_ear.x)\n",
    "            right_eye_to_ear = abs(right_eye_center.x - right_ear.x)\n",
    "            if left_eye_to_ear > right_eye_to_ear + 0.03:\n",
    "                head_lr = \"LEFT\"\n",
    "            elif right_eye_to_ear > left_eye_to_ear + 0.03:\n",
    "                head_lr = \"RIGHT\"\n",
    "            else:\n",
    "                head_lr = \"CENTER\"\n",
    "\n",
    "            # ÏÉÅÌïò (Îàà ‚Üí Ïñ¥Íπ® Ï§ëÍ∞ÑÏ†ê ÎÜíÏù¥ ÎπÑÍµê)\n",
    "            nose_y = (left_eye_center.y + right_eye_center.y) / 2\n",
    "            shoulder_y = (pose_lm[LEFT_SHOULDER].y + pose_lm[RIGHT_SHOULDER].y) / 2\n",
    "            head_ud = str(nose_y) + str(shoulder_y)\n",
    "\n",
    "            # if nose_y < shoulder_y - 0.05:\n",
    "            #     head_ud = \"UP\"\n",
    "            # elif nose_y > shoulder_y + 0.05:\n",
    "            #     head_ud = \"DOWN\"\n",
    "            # else:\n",
    "            #     head_ud = \"CENTER\"\n",
    "\n",
    "            head_text = f\"Head: {head_lr} / {head_ud}\"\n",
    "\n",
    "    # === Ïñ¥Íπ® Í∏∞Ïö∏Í∏∞ ===\n",
    "    if pose_result.pose_landmarks:\n",
    "        lm = pose_result.pose_landmarks.landmark\n",
    "        diff = lm[LEFT_SHOULDER].y - lm[RIGHT_SHOULDER].y\n",
    "        if diff > 0.012:\n",
    "            shoulder_text = \"LEFT SHOULDER UP\"\n",
    "        elif diff < -0.012:\n",
    "            shoulder_text = \"RIGHT SHOULDER UP\"\n",
    "        else:\n",
    "            shoulder_text = \"SHOULDERS STRAIGHT\"\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_result.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "        )\n",
    "\n",
    "    # Ï∂úÎ†•\n",
    "    y = 30\n",
    "    for text in [gaze_text, head_text, shoulder_text]:\n",
    "        if text:\n",
    "            cv2.putText(frame, text, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            y += 30\n",
    "\n",
    "    cv2.imshow(\"Gaze + Head + Shoulder (Full)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0245fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏãúÏÑ†, Í≥†Í∞úÎßå ÏúÑÏïÑÎûò - chat gpt ÏàòÏπò Í∑∏ÎåÄÎ°ú - Í≥†Í∞ú ÏóÑÏ≤≠ ÏúÑÎ°ú Îì§Ïñ¥Ïïº center.  ÏãúÏÑ†ÏùÄ ÏïÑÏòà ÏïàÎê®.\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ÏõπÏ∫† Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # ÏãúÏÑ† ÌåêÎã® Í∏∞Ï§Ä ÎûúÎìúÎßàÌÅ¨ (ÏôºÏ™Ω Îàà Í∏∞Ï§Ä)\n",
    "            iris_y = face_landmarks.landmark[468].y\n",
    "            eye_top_y = face_landmarks.landmark[159].y\n",
    "            eye_bottom_y = face_landmarks.landmark[145].y\n",
    "\n",
    "            # ÏãúÏÑ† Î∞©Ìñ• ÌåêÎ≥Ñ\n",
    "            if iris_y < eye_top_y - 0.005:\n",
    "                gaze_direction = \"üëÅÔ∏è UP\"\n",
    "            elif iris_y > eye_bottom_y + 0.005:\n",
    "                gaze_direction = \"üëÅÔ∏è DOWN\"\n",
    "            else:\n",
    "                gaze_direction = \"üëÅÔ∏è CENTER\"\n",
    "\n",
    "            # Í≥†Í∞ú Î∞©Ìñ• ÌåêÎã® Í∏∞Ï§Ä (Îàà, ÏΩîÎÅù, ÌÑ±)\n",
    "            left_eye_y = (face_landmarks.landmark[33].y + face_landmarks.landmark[133].y) / 2\n",
    "            nose_y = face_landmarks.landmark[1].y\n",
    "            chin_y = face_landmarks.landmark[152].y\n",
    "\n",
    "            # Í≥†Í∞ú Î∞©Ìñ• ÌåêÎ≥Ñ\n",
    "            if nose_y < left_eye_y - 0.02:\n",
    "                head_direction = \"üßë‚Äçü¶∞ HEAD UP\"\n",
    "            elif nose_y > left_eye_y + 0.02:\n",
    "                head_direction = \"üßë‚Äçü¶∞ HEAD DOWN\"\n",
    "            else:\n",
    "                head_direction = \"üßë‚Äçü¶∞ HEAD CENTER\"\n",
    "\n",
    "            # ÏãúÍ∞ÅÌôî\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                face_landmarks,\n",
    "                mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "            )\n",
    "\n",
    "            cv2.putText(frame, gaze_direction, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, head_direction, (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 128, 0), 2)\n",
    "\n",
    "    cv2.imshow('Gaze & Head Direction (Vertical)', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5999424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏãúÏÑ†, Í≥†Í∞úÎßå ÏúÑÏïÑÎûò - chat gpt ÏàòÏπòÎßå ÏàòÏ†ï - Ïûò ÏïàÎê®\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ÏõπÏ∫† Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # ÏãúÏÑ† ÌåêÎã® Í∏∞Ï§Ä ÎûúÎìúÎßàÌÅ¨ (ÏôºÏ™Ω Îàà Í∏∞Ï§Ä)\n",
    "            iris_y = face_landmarks.landmark[468].y\n",
    "            eye_top_y = face_landmarks.landmark[159].y\n",
    "            eye_bottom_y = face_landmarks.landmark[145].y\n",
    "\n",
    "            # ÏãúÏÑ† Î∞©Ìñ• ÌåêÎ≥Ñ\n",
    "            if iris_y < eye_top_y - 0.005:\n",
    "                gaze_direction = \"UP\"\n",
    "            elif iris_y > eye_bottom_y + 0.005:\n",
    "                gaze_direction = \"DOWN\"\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "\n",
    "            # Í≥†Í∞ú Î∞©Ìñ• ÌåêÎã® Í∏∞Ï§Ä (Îàà, ÏΩîÎÅù, ÌÑ±)\n",
    "            left_eye_y = (face_landmarks.landmark[33].y + face_landmarks.landmark[133].y) / 2\n",
    "            nose_y = face_landmarks.landmark[1].y\n",
    "            chin_y = face_landmarks.landmark[152].y\n",
    "\n",
    "            # Í≥†Í∞ú Î∞©Ìñ• ÌåêÎ≥Ñ\n",
    "            if nose_y < left_eye_y - 0.3:   # 0.4 < 0.8 -0.3 (0.5)\n",
    "                head_direction = \"HEAD UP\"\n",
    "            elif nose_y > left_eye_y - 0.5:   # 0.4 > 0.8 -0.5 (0.3)\n",
    "                head_direction = \"HEAD DOWN\"\n",
    "            else:\n",
    "                head_direction = \"HEAD CENTER\"\n",
    "\n",
    "            # ÏãúÍ∞ÅÌôî\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                face_landmarks,\n",
    "                mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "            )\n",
    "\n",
    "            cv2.putText(frame, gaze_direction, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, head_direction, (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 128, 0), 2)\n",
    "\n",
    "    cv2.imshow('Gaze & Head Direction (Vertical)', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3908b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõπÏ∫† ÏãúÏÑ† Í≥†Í∞ú ÌåêÎã® Ï±ÑÌåÖÏ∞Ω -> MediaPipe + solvePnP Ï°∞Ìï©ÏúºÎ°ú Í≥†Í∞ú & ÏãúÏÑ† ÏúÑ/ÏïÑÎûò Ïã§ÏãúÍ∞Ñ ÌåêÎã®ÌïòÎäî ÏôÑÏÑ± ÏΩîÎìú ÏûëÏÑ±Ìï¥Ï§ò\n",
    "# ÏúÑÏïÑÎûò Í≥†Í∞úÎäî ÏûòÎê® -> but ÏúÑÎ°úÎäî Ï°∞Í∏à Îçî Îì§Ïñ¥Ïïº up, ÏïÑÎûòÎ°úÎäî Îçú ÎÇ¥Î†§ÎèÑ down ÎêòÍ≤å. pitch > -15,   pitch > 5\n",
    "# ÏãúÏÑ†ÏùÄ Ïûò ÏïàÎê®. -> ÍµâÏû•Ìûà ÏúÑÎ•º Î∞îÎùºÎ≥º ÎïåÎßå, ÏúÑÍ∞Ä Îú∏. ÏïÑÎûòÎäî Ïûò Ïïà Îê®.\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from math import degrees\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# ÏñºÍµ¥Ïùò 3D Î™®Îç∏ Ï¢åÌëú (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),          # Nose tip - landmark 1\n",
    "    (0.0, -63.6, -12.5),      # Chin - landmark 152\n",
    "    (-43.3, 32.7, -26.0),     # Left eye left corner - landmark 33\n",
    "    (43.3, 32.7, -26.0),      # Right eye right corner - landmark 263\n",
    "    (-28.9, -28.9, -24.1),    # Left Mouth corner - landmark 78\n",
    "    (28.9, -28.9, -24.1)      # Right Mouth corner - landmark 308\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï (ÏûÑÏùòÏùò ÎÇ¥Î∂Ä ÌååÎùºÎØ∏ÌÑ∞)\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "# ÏõπÏ∫† Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # 2D Ïù¥ÎØ∏ÏßÄ Ï¢åÌëú: solvePnPÏö©\n",
    "        image_points = np.array([\n",
    "            [face_landmarks[1].x * w, face_landmarks[1].y * h],     # Nose tip\n",
    "            [face_landmarks[152].x * w, face_landmarks[152].y * h], # Chin\n",
    "            [face_landmarks[33].x * w, face_landmarks[33].y * h],   # Left eye left corner\n",
    "            [face_landmarks[263].x * w, face_landmarks[263].y * h], # Right eye right corner\n",
    "            [face_landmarks[78].x * w, face_landmarks[78].y * h],   # Left mouth corner\n",
    "            [face_landmarks[308].x * w, face_landmarks[308].y * h]  # Right mouth corner\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))  # ÏôúÍ≥° Î¨¥Ïãú\n",
    "\n",
    "        # solvePnP ‚Üí Í≥†Í∞ú ÌöåÏ†Ñ Î≤°ÌÑ∞\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        # ÌöåÏ†Ñ ÌñâÎ†¨Î°ú Î≥ÄÌôò\n",
    "        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "        pitch = degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "        # Í≥†Í∞ú ÏúÑ/ÏïÑÎûò ÌåêÎã®\n",
    "        if pitch > 5:\n",
    "            head_direction = \"Head Down\"\n",
    "        elif pitch < -15:\n",
    "            head_direction = \"Head Up\"\n",
    "        else:\n",
    "            head_direction = \"Head Center\"\n",
    "\n",
    "        # ÏãúÏÑ† ÏúÑ/ÏïÑÎûò ÌåêÎã® (ÏôºÏ™Ω Îàà Í∏∞Ï§Ä)\n",
    "        iris_y = face_landmarks[468].y\n",
    "        eye_top_y = face_landmarks[159].y\n",
    "        eye_bottom_y = face_landmarks[145].y\n",
    "        iris_ratio = (iris_y - eye_top_y) / (eye_bottom_y - eye_top_y)\n",
    "\n",
    "        if iris_ratio < 0.4:\n",
    "            gaze_direction = \"Gaze Up\"\n",
    "        elif iris_ratio > 0.6:\n",
    "            gaze_direction = \"Gaze Down\"\n",
    "        else:\n",
    "            gaze_direction = \"Gaze Center\"\n",
    "\n",
    "        # ÏãúÍ∞ÅÌôî\n",
    "        cv2.putText(frame, f\"{head_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 128, 0), 2)\n",
    "        cv2.putText(frame, f\"{gaze_direction}\", (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Head & Gaze Pitch Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "addf1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõπÏ∫† ÏãúÏÑ† Í≥†Í∞ú ÌåêÎã® Ï±ÑÌåÖÏ∞Ω -> MediaPipe + solvePnP Ï°∞Ìï©ÏúºÎ°ú Í≥†Í∞ú & ÏãúÏÑ† ÏúÑ/ÏïÑÎûò Ïã§ÏãúÍ∞Ñ ÌåêÎã®ÌïòÎäî ÏôÑÏÑ± ÏΩîÎìú ÏûëÏÑ±Ìï¥Ï§ò\n",
    "# ÏúÑÏïÑÎûò Í≥†Í∞úÎäî ÏûòÎê® -> ÏàòÏπò Î≤îÏúÑ -> ÏàòÏ†ï\n",
    "# ÏãúÏÑ†ÏùÄ Ïûò ÏïàÎê®. -> ÍµâÏû•Ìûà ÏúÑÎ•º Î∞îÎùºÎ≥º ÎïåÎßå, ÏúÑÍ∞Ä Îú∏. ÏïÑÎûòÎäî Ïûò Ïïà Îê®.\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from math import degrees\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# ÏñºÍµ¥Ïùò 3D Î™®Îç∏ Ï¢åÌëú (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),          # Nose tip - landmark 1\n",
    "    (0.0, -63.6, -12.5),      # Chin - landmark 152\n",
    "    (-43.3, 32.7, -26.0),     # Left eye left corner - landmark 33\n",
    "    (43.3, 32.7, -26.0),      # Right eye right corner - landmark 263\n",
    "    (-28.9, -28.9, -24.1),    # Left Mouth corner - landmark 78\n",
    "    (28.9, -28.9, -24.1)      # Right Mouth corner - landmark 308\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï (ÏûÑÏùòÏùò ÎÇ¥Î∂Ä ÌååÎùºÎØ∏ÌÑ∞)\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "# ÏõπÏ∫† Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # 2D Ïù¥ÎØ∏ÏßÄ Ï¢åÌëú: solvePnPÏö©\n",
    "        image_points = np.array([\n",
    "            [face_landmarks[1].x * w, face_landmarks[1].y * h],     # Nose tip\n",
    "            [face_landmarks[152].x * w, face_landmarks[152].y * h], # Chin\n",
    "            [face_landmarks[33].x * w, face_landmarks[33].y * h],   # Left eye left corner\n",
    "            [face_landmarks[263].x * w, face_landmarks[263].y * h], # Right eye right corner\n",
    "            [face_landmarks[78].x * w, face_landmarks[78].y * h],   # Left mouth corner\n",
    "            [face_landmarks[308].x * w, face_landmarks[308].y * h]  # Right mouth corner\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))  # ÏôúÍ≥° Î¨¥Ïãú\n",
    "\n",
    "        # solvePnP ‚Üí Í≥†Í∞ú ÌöåÏ†Ñ Î≤°ÌÑ∞\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        # ÌöåÏ†Ñ ÌñâÎ†¨Î°ú Î≥ÄÌôò\n",
    "        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "        pitch = degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "        # Í≥†Í∞ú ÏúÑ/ÏïÑÎûò ÌåêÎã®\n",
    "        if pitch > 15:      # 5 -> 15  (Îçî Í≥†Í∞ú Îì§Ïñ¥Ïïº ÎêòÍ≤å)\n",
    "            head_direction = \"Head Down\"\n",
    "        elif pitch < -2:    # -15 -> -2   (Îçú Í≥†Í∞ú ÏàôÏù¥ÏßÄ ÏïäÏïÑÎèÑ ÎêòÍ≤å)\n",
    "            head_direction = \"Head Up\"\n",
    "        else:\n",
    "            head_direction = \"Head Center\"\n",
    "\n",
    "        # ÏãúÏÑ† ÏúÑ/ÏïÑÎûò ÌåêÎã® (ÏôºÏ™Ω Îàà Í∏∞Ï§Ä)\n",
    "        iris_y = face_landmarks[468].y\n",
    "        eye_top_y = face_landmarks[159].y\n",
    "        eye_bottom_y = face_landmarks[145].y\n",
    "        iris_ratio = (iris_y - eye_top_y) / (eye_bottom_y - eye_top_y)\n",
    "\n",
    "        if iris_ratio < 0.4:\n",
    "            gaze_direction = \"Gaze Up\"\n",
    "        elif iris_ratio > 0.6:\n",
    "            gaze_direction = \"Gaze Down\"\n",
    "        else:\n",
    "            gaze_direction = \"Gaze Center\"\n",
    "\n",
    "        # ÏãúÍ∞ÅÌôî\n",
    "        cv2.putText(frame, f\"{head_direction}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 128, 0), 2)\n",
    "        cv2.putText(frame, f\"{gaze_direction}\", (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Head & Gaze Pitch Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8ad8cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gaze_tracking'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mgaze_tracking\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m GazeTracking\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmediapipe\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# GazeTracking Ï¥àÍ∏∞Ìôî\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gaze_tracking'"
     ]
    }
   ],
   "source": [
    "# ÏãúÏÑ†ÎïåÎ¨∏Ïóê gaze tracking Ìï¥Î≥¥Î†§Í≥† ÌñàÎäîÎç∞, ÏïàÎèº -> ÏÑ§Ïπò Ïñ¥Î†§ÏõåÏÑú Ïã§Ìå® 0.0.8 Î∞õÍ∏∞Í∞Ä ÌûòÎì¨.\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from gaze_tracking import GazeTracking\n",
    "import mediapipe as mp\n",
    "\n",
    "# GazeTracking Ï¥àÍ∏∞Ìôî\n",
    "gaze = GazeTracking()\n",
    "\n",
    "# MediaPipe FaceMesh Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏ (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),          # Nose tip\n",
    "    (0.0, -63.6, -12.5),      # Chin\n",
    "    (-43.3, 32.7, -26.0),     # Left eye corner\n",
    "    (43.3, 32.7, -26.0),      # Right eye corner\n",
    "    (-28.9, -28.9, -24.1),    # Left mouth\n",
    "    (28.9, -28.9, -24.1)      # Right mouth\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ïÏö© Î≥ÄÏàò\n",
    "gaze_state = None\n",
    "gaze_start_time = time.time()\n",
    "gaze_duration_dict = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Ïπ¥Î©îÎùº Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # GazeTracking Î∂ÑÏÑù\n",
    "    gaze.refresh(frame)\n",
    "    vertical_ratio = gaze.vertical_ratio()\n",
    "    gaze_text = \"Gaze: Unknown\"\n",
    "\n",
    "    if vertical_ratio is not None:\n",
    "        if vertical_ratio < 0.35:\n",
    "            gaze_direction = \"UP\"\n",
    "        elif vertical_ratio > 0.65:\n",
    "            gaze_direction = \"DOWN\"\n",
    "        else:\n",
    "            gaze_direction = \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Í∏∞Î°ù\n",
    "        now = time.time()\n",
    "        if gaze_direction != gaze_state:\n",
    "            if gaze_state:\n",
    "                gaze_duration_dict[gaze_state] += now - gaze_start_time\n",
    "            gaze_start_time = now\n",
    "            gaze_state = gaze_direction\n",
    "\n",
    "    # MediaPipeÎ°ú Í≥†Í∞ú Î∞©Ìñ• (pitch) Í≥ÑÏÇ∞\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    pitch_text = \"Head: Unknown\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        image_points = np.array([\n",
    "            [face_landmarks[1].x * w, face_landmarks[1].y * h],\n",
    "            [face_landmarks[152].x * w, face_landmarks[152].y * h],\n",
    "            [face_landmarks[33].x * w, face_landmarks[33].y * h],\n",
    "            [face_landmarks[263].x * w, face_landmarks[263].y * h],\n",
    "            [face_landmarks[78].x * w, face_landmarks[78].y * h],\n",
    "            [face_landmarks[308].x * w, face_landmarks[308].y * h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "            pitch = np.degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "            if pitch < 15:\n",
    "                pitch_text = \"Head: UP\"\n",
    "            elif pitch > -2:\n",
    "                pitch_text = \"Head: DOWN\"\n",
    "            else:\n",
    "                pitch_text = \"Head: CENTER\"\n",
    "\n",
    "    # Í≤∞Í≥º Ï∂úÎ†•\n",
    "    display_text = f\"{gaze_text} | {pitch_text}\"\n",
    "    cv2.putText(frame, display_text, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    for i, (k, v) in enumerate(gaze_duration_dict.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (30, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Gaze & Head Pitch Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ÎßàÏßÄÎßâ ÏãúÏÑ† ÎàÑÏ†Å\n",
    "if gaze_state:\n",
    "    gaze_duration_dict[gaze_state] += time.time() - gaze_start_time\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nÏ¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\")\n",
    "for direction, duration in gaze_duration_dict.items():\n",
    "    print(f\"{direction}: {duration:.2f}Ï¥à\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92c0e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gaze-tracking\n",
      "  Downloading gaze_tracking-0.0.1-py3-none-any.whl.metadata (595 bytes)\n",
      "Downloading gaze_tracking-0.0.1-py3-none-any.whl (1.3 kB)\n",
      "Installing collected packages: gaze-tracking\n",
      "Successfully installed gaze-tracking-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gaze-tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ea7d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ï¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\n",
      "UP: 23.56Ï¥à\n",
      "DOWN: 0.00Ï¥à\n",
      "CENTER: 30.16Ï¥à\n"
     ]
    }
   ],
   "source": [
    "# gaze tracking ÏóÜÏï∞. ÏãúÏÑ† ÏúÑÏïÑÎûòÎäî mediapipeÎ°ú ÏßÑÌñâÌï¥ÏïºÌï† ÎìØ. -> ÏàòÏπò Ï°∞Ï†ïÏ§ë\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏ (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -63.6, -12.5),\n",
    "    (-43.3, 32.7, -26.0),\n",
    "    (43.3, 32.7, -26.0),\n",
    "    (-28.9, -28.9, -24.1),\n",
    "    (28.9, -28.9, -24.1)\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ïÏö©\n",
    "gaze_state = None\n",
    "gaze_start_time = time.time()\n",
    "gaze_duration_dict = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    gaze_text = \"Gaze: Unknown\"\n",
    "    pitch_text = \"Head: Unknown\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # --- ÏãúÏÑ† Î∂ÑÏÑù ---\n",
    "        left_ratio = (landmarks[468].y - landmarks[159].y) / (landmarks[145].y - landmarks[159].y)\n",
    "        right_ratio = (landmarks[473].y - landmarks[386].y) / (landmarks[374].y - landmarks[386].y)\n",
    "        iris_ratio = (left_ratio + right_ratio) / 2\n",
    "\n",
    "        if iris_ratio < 0.40:\n",
    "            gaze_direction = \"UP\"\n",
    "        elif iris_ratio > 0.60:\n",
    "            gaze_direction = \"DOWN\"\n",
    "        else:\n",
    "            gaze_direction = \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "        now = time.time()\n",
    "        if gaze_direction != gaze_state:\n",
    "            if gaze_state:\n",
    "                gaze_duration_dict[gaze_state] += now - gaze_start_time\n",
    "            gaze_start_time = now\n",
    "            gaze_state = gaze_direction\n",
    "\n",
    "        # --- Í≥†Í∞ú Î∞©Ìñ•(pitch) Î∂ÑÏÑù ---\n",
    "        image_points = np.array([\n",
    "            [landmarks[1].x * w, landmarks[1].y * h],\n",
    "            [landmarks[152].x * w, landmarks[152].y * h],\n",
    "            [landmarks[33].x * w, landmarks[33].y * h],\n",
    "            [landmarks[263].x * w, landmarks[263].y * h],\n",
    "            [landmarks[78].x * w, landmarks[78].y * h],\n",
    "            [landmarks[308].x * w, landmarks[308].y * h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "            pitch = np.degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "            if pitch < -15:\n",
    "                pitch_text = \"Head: UP\"\n",
    "            elif pitch > 5:\n",
    "                pitch_text = \"Head: DOWN\"\n",
    "            else:\n",
    "                pitch_text = \"Head: CENTER\"\n",
    "\n",
    "    # --- Í≤∞Í≥º Ï∂úÎ†• ---\n",
    "    display_text = f\"{gaze_text} | {pitch_text}\"\n",
    "    cv2.putText(frame, display_text, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    for i, (k, v) in enumerate(gaze_duration_dict.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (30, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Gaze & Head Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ÎßàÏßÄÎßâ ÏãúÏÑ† ÎàÑÏ†Å\n",
    "if gaze_state:\n",
    "    gaze_duration_dict[gaze_state] += time.time() - gaze_start_time\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nÏ¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\")\n",
    "for direction, duration in gaze_duration_dict.items():\n",
    "    print(f\"{direction}: {duration:.2f}Ï¥à\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12dc63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calibration] iris_avg=0.401, up<0.321, down>0.481\n",
      "\n",
      "Ï¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\n",
      "UP: 29.81Ï¥à\n",
      "DOWN: 66.86Ï¥à\n",
      "CENTER: 455.62Ï¥à\n"
     ]
    }
   ],
   "source": [
    "# Ï¥àÎ∞ò 30ÌîÑÎ†àÏûÑ Ï∞çÏñ¥ÏÑú ÌôçÏ±Ñ ÏúÑÏπò ÎπÑÏú® ÌèâÍ∑†(avg_ratio) Ï∏°Ï†ï ÌõÑ ÏãúÏÑ† Í∞êÏßÄ -> Ïûò ÏïàÎê® Ï°∞Í∏à ÎÇòÏïÑÏßê\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏ (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -63.6, -12.5),\n",
    "    (-43.3, 32.7, -26.0),\n",
    "    (43.3, 32.7, -26.0),\n",
    "    (-28.9, -28.9, -24.1),\n",
    "    (28.9, -28.9, -24.1)\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ïÏö©\n",
    "gaze_state = None\n",
    "gaze_start_time = time.time()\n",
    "gaze_duration_dict = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "# --- ÏãúÏÑ† ÎπÑÏú® ÏûêÎèô Î≥¥Ï†ïÏö© ---\n",
    "calibration_ratios = []\n",
    "frame_idx = 0\n",
    "is_calibrated = False\n",
    "up_thresh = 0.0\n",
    "down_thresh = 1.0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    gaze_text = \"Gaze: Unknown\"\n",
    "    pitch_text = \"Head: Unknown\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # --- ÏãúÏÑ† Î∂ÑÏÑù ---\n",
    "        left_ratio = (landmarks[468].y - landmarks[159].y) / (landmarks[145].y - landmarks[159].y)\n",
    "        right_ratio = (landmarks[473].y - landmarks[386].y) / (landmarks[374].y - landmarks[386].y)\n",
    "        iris_ratio = (left_ratio + right_ratio) / 2\n",
    "\n",
    "        # ÏûêÎèô Î≥¥Ï†ï Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò (Ï¥àÍ∏∞ 30ÌîÑÎ†àÏûÑ ÌèâÍ∑†)\n",
    "        if not is_calibrated:\n",
    "            calibration_ratios.append(iris_ratio)\n",
    "            frame_idx += 1\n",
    "            if frame_idx == 30:\n",
    "                avg_ratio = np.mean(calibration_ratios)\n",
    "                up_thresh = avg_ratio - 0.08\n",
    "                down_thresh = avg_ratio + 0.08\n",
    "                is_calibrated = True\n",
    "                print(f\"[Calibration] iris_avg={avg_ratio:.3f}, up<{up_thresh:.3f}, down>{down_thresh:.3f}\")\n",
    "            gaze_direction = \"CENTER\"\n",
    "        else:\n",
    "            if iris_ratio < up_thresh:\n",
    "                gaze_direction = \"UP\"\n",
    "            elif iris_ratio > down_thresh:\n",
    "                gaze_direction = \"DOWN\"\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "        now = time.time()\n",
    "        if gaze_direction != gaze_state:\n",
    "            if gaze_state:\n",
    "                gaze_duration_dict[gaze_state] += now - gaze_start_time\n",
    "            gaze_start_time = now\n",
    "            gaze_state = gaze_direction\n",
    "\n",
    "        # --- Í≥†Í∞ú Î∞©Ìñ•(pitch) Î∂ÑÏÑù ---\n",
    "        image_points = np.array([\n",
    "            [landmarks[1].x * w, landmarks[1].y * h],\n",
    "            [landmarks[152].x * w, landmarks[152].y * h],\n",
    "            [landmarks[33].x * w, landmarks[33].y * h],\n",
    "            [landmarks[263].x * w, landmarks[263].y * h],\n",
    "            [landmarks[78].x * w, landmarks[78].y * h],\n",
    "            [landmarks[308].x * w, landmarks[308].y * h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "            pitch = np.degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "            if pitch < -15:\n",
    "                pitch_text = \"Head: UP\"\n",
    "            elif pitch > 5:\n",
    "                pitch_text = \"Head: DOWN\"\n",
    "            else:\n",
    "                pitch_text = \"Head: CENTER\"\n",
    "\n",
    "    # --- Í≤∞Í≥º Ï∂úÎ†• ---\n",
    "    display_text = f\"{gaze_text} | {pitch_text}\"\n",
    "    cv2.putText(frame, display_text, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    for i, (k, v) in enumerate(gaze_duration_dict.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (30, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Gaze & Head Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ÎßàÏßÄÎßâ ÏãúÏÑ† ÎàÑÏ†Å\n",
    "if gaze_state:\n",
    "    gaze_duration_dict[gaze_state] += time.time() - gaze_start_time\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nÏ¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\")\n",
    "for direction, duration in gaze_duration_dict.items():\n",
    "    print(f\"{direction}: {duration:.2f}Ï¥à\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e80a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calibration] eye_opening_avg=0.0195, up<0.0176, down>0.0215\n",
      "\n",
      "Ï¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\n",
      "UP: 57.83Ï¥à\n",
      "DOWN: 93.58Ï¥à\n",
      "CENTER: 70.07Ï¥à\n"
     ]
    }
   ],
   "source": [
    "# ÏúóÎààÍ∫ºÌíÄÍ≥º ÏïÑÎû´ ÎààÍ∫ºÌíÄÏùò Í±∞Î¶¨ Ï∞®Ïù¥ -> Îú®Î©¥ Ï¢ÅÏïÑÏßÄÍ≥†, Í∞êÏúºÎ©¥ Í∏∏Ïñ¥Ïßê.\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏ (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -63.6, -12.5),\n",
    "    (-43.3, 32.7, -26.0),\n",
    "    (43.3, 32.7, -26.0),\n",
    "    (-28.9, -28.9, -24.1),\n",
    "    (28.9, -28.9, -24.1)\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ïÏö©\n",
    "gaze_state = None\n",
    "gaze_start_time = time.time()\n",
    "gaze_duration_dict = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "# --- ÎààÍ∫ºÌíÄ Í∏∞Î∞ò ÏûêÎèô Î≥¥Ï†ïÏö© ---\n",
    "calibration_openings = []\n",
    "frame_idx = 0\n",
    "is_calibrated = False\n",
    "up_thresh = 0.0\n",
    "down_thresh = 1.0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    gaze_text = \"Gaze: Unknown\"\n",
    "    pitch_text = \"Head: Unknown\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # --- ÏãúÏÑ† Î∂ÑÏÑù (ÎààÍ∫ºÌíÄ Ïó¥Î¶º Ï†ïÎèÑ) ---\n",
    "        eye_top_id = 159\n",
    "        eye_bottom_id = 145\n",
    "        iris_id = 468\n",
    "\n",
    "        eye_top = landmarks[eye_top_id].y\n",
    "        eye_bottom = landmarks[eye_bottom_id].y\n",
    "        eye_opening = abs(eye_top - eye_bottom)\n",
    "\n",
    "        # Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò (Ï¥àÍ∏∞ 30ÌîÑÎ†àÏûÑ ÌèâÍ∑†)\n",
    "        if not is_calibrated:\n",
    "            calibration_openings.append(eye_opening)\n",
    "            frame_idx += 1\n",
    "            if frame_idx == 30:\n",
    "                avg_opening = np.mean(calibration_openings)\n",
    "                up_thresh = avg_opening * 0.9\n",
    "                down_thresh = avg_opening * 1.1\n",
    "                is_calibrated = True\n",
    "                print(f\"[Calibration] eye_opening_avg={avg_opening:.4f}, up<{up_thresh:.4f}, down>{down_thresh:.4f}\")\n",
    "            gaze_direction = \"CENTER\"\n",
    "        else:\n",
    "            if eye_opening < up_thresh:\n",
    "                gaze_direction = \"DOWN\"\n",
    "            elif eye_opening > down_thresh:\n",
    "                gaze_direction = \"UP\"\n",
    "            else:\n",
    "                gaze_direction = \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "        now = time.time()\n",
    "        if gaze_direction != gaze_state:\n",
    "            if gaze_state:\n",
    "                gaze_duration_dict[gaze_state] += now - gaze_start_time\n",
    "            gaze_start_time = now\n",
    "            gaze_state = gaze_direction\n",
    "\n",
    "        # --- ÎûúÎìúÎßàÌÅ¨ ÏãúÍ∞ÅÌôî ---\n",
    "        def draw_landmark_circle(idx, color):\n",
    "            cx = int(landmarks[idx].x * w)\n",
    "            cy = int(landmarks[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 4, color, -1)\n",
    "\n",
    "        draw_landmark_circle(eye_top_id, (0, 255, 0))      # ÏúóÎààÍ∫ºÌíÄ Ï¥àÎ°ù\n",
    "        draw_landmark_circle(eye_bottom_id, (0, 0, 255))   # ÏïÑÎû´ÎààÍ∫ºÌíÄ Îπ®Í∞ï\n",
    "        draw_landmark_circle(iris_id, (255, 0, 0))         # ÎèôÍ≥µ ÌååÎûë\n",
    "\n",
    "        # --- Í≥†Í∞ú Î∞©Ìñ•(pitch) Î∂ÑÏÑù ---\n",
    "        image_points = np.array([\n",
    "            [landmarks[1].x * w, landmarks[1].y * h],\n",
    "            [landmarks[152].x * w, landmarks[152].y * h],\n",
    "            [landmarks[33].x * w, landmarks[33].y * h],\n",
    "            [landmarks[263].x * w, landmarks[263].y * h],\n",
    "            [landmarks[78].x * w, landmarks[78].y * h],\n",
    "            [landmarks[308].x * w, landmarks[308].y * h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "            pitch = np.degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "            if pitch < -15:\n",
    "                pitch_text = \"Head: UP\"\n",
    "            elif pitch > 5:\n",
    "                pitch_text = \"Head: DOWN\"\n",
    "            else:\n",
    "                pitch_text = \"Head: CENTER\"\n",
    "\n",
    "    # --- Í≤∞Í≥º Ï∂úÎ†• ---\n",
    "    display_text = f\"{gaze_text} | {pitch_text}\"\n",
    "    cv2.putText(frame, display_text, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    for i, (k, v) in enumerate(gaze_duration_dict.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (30, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Gaze & Head Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ÎßàÏßÄÎßâ ÏãúÏÑ† ÎàÑÏ†Å\n",
    "if gaze_state:\n",
    "    gaze_duration_dict[gaze_state] += time.time() - gaze_start_time\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nÏ¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\")\n",
    "for direction, duration in gaze_duration_dict.items():\n",
    "    print(f\"{direction}: {duration:.2f}Ï¥à\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e114ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Calibration] eye_opening_avg=0.0212, up>0.0234, down<0.0191\n",
      "\n",
      "Ï¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\n",
      "UP: 34.96Ï¥à\n",
      "DOWN: 47.14Ï¥à\n",
      "CENTER: 47.76Ï¥à\n"
     ]
    }
   ],
   "source": [
    "# | Ï°∞Í±¥                                  | ÎèôÏûë                     |\n",
    "# | ------------------------------------ | ------------------------ |\n",
    "# | ÎààÏù¥ Í±∞Ïùò Îã´ÌòîÏùÑ Îïå (`eye_opening < 0.015`) | ÍπúÎπ°ÏûÑÏúºÎ°ú ÌåêÎã® ‚Üí Ïù¥Ï†Ñ ÏãúÏÑ† ÏÉÅÌÉú Ïú†ÏßÄ |\n",
    "# | ÍπúÎπ°ÏûÑ ÏßÅÌõÑ ÏùºÏ†ï ÌîÑÎ†àÏûÑ(`5 frame`) ÎèôÏïà      | Ïó¨Ï†ÑÌûà Ïù¥Ï†Ñ ÏãúÏÑ† ÏÉÅÌÉú Ïú†ÏßÄ (Ïø®Îã§Ïö¥)  |\n",
    "# -> Í¥úÏ∞ÆÍ≤å ÎÇòÏò§Îäî Ìé∏ -> ÏàòÏπò Ï¢Ä Ï°∞Ï†àÌï¥ÏïºÌï† ÎìØ\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)\n",
    "\n",
    "# 3D Î™®Îç∏ Ìè¨Ïù∏Ìä∏ (solvePnPÏö©)\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -63.6, -12.5),\n",
    "    (-43.3, 32.7, -26.0),\n",
    "    (43.3, 32.7, -26.0),\n",
    "    (-28.9, -28.9, -24.1),\n",
    "    (28.9, -28.9, -24.1)\n",
    "], dtype=np.float32)\n",
    "\n",
    "# ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ïÏö©\n",
    "gaze_state = None\n",
    "gaze_start_time = time.time()\n",
    "gaze_duration_dict = {\"UP\": 0.0, \"DOWN\": 0.0, \"CENTER\": 0.0}\n",
    "\n",
    "# Ïπ¥Î©îÎùº ÏÑ§Ï†ï\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def get_camera_matrix(w, h):\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    return np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "# --- ÎààÍ∫ºÌíÄ Í∏∞Î∞ò ÏûêÎèô Î≥¥Ï†ïÏö© ---\n",
    "calibration_openings = []\n",
    "frame_idx = 0\n",
    "is_calibrated = False\n",
    "up_thresh = 0.0\n",
    "down_thresh = 1.0\n",
    "\n",
    "# --- ÍπúÎπ°ÏûÑ Í∞êÏßÄÏö© ---\n",
    "blink_threshold = 0.015\n",
    "blink_cooldown_frames = 5\n",
    "blink_cooldown_counter = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    gaze_text = \"Gaze: Unknown\"\n",
    "    pitch_text = \"Head: Unknown\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # --- ÏãúÏÑ† Î∂ÑÏÑù (ÎààÍ∫ºÌíÄ Ïó¥Î¶º Ï†ïÎèÑ) ---\n",
    "        eye_top_id = 159\n",
    "        eye_bottom_id = 145\n",
    "        iris_id = 468\n",
    "\n",
    "        eye_top = landmarks[eye_top_id].y\n",
    "        eye_bottom = landmarks[eye_bottom_id].y\n",
    "        eye_opening = abs(eye_top - eye_bottom)\n",
    "\n",
    "        # ÍπúÎπ°ÏûÑ Ï≤òÎ¶¨\n",
    "        if eye_opening < blink_threshold:\n",
    "            blink_cooldown_counter = blink_cooldown_frames\n",
    "            gaze_direction = gaze_state  # ÍπúÎπ°Ïùº ÎïåÎäî Ïù¥Ï†Ñ ÏÉÅÌÉú Ïú†ÏßÄ\n",
    "        elif blink_cooldown_counter > 0:\n",
    "            blink_cooldown_counter -= 1\n",
    "            gaze_direction = gaze_state  # Ïø®Îã§Ïö¥ ÎèôÏïàÎèÑ Ïú†ÏßÄ\n",
    "        else:\n",
    "            # Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò (Ï¥àÍ∏∞ 30ÌîÑÎ†àÏûÑ ÌèâÍ∑†)\n",
    "            if not is_calibrated:\n",
    "                calibration_openings.append(eye_opening)\n",
    "                frame_idx += 1\n",
    "                if frame_idx == 30:\n",
    "                    avg_opening = np.mean(calibration_openings)\n",
    "                    up_thresh = avg_opening * 1.1\n",
    "                    down_thresh = avg_opening * 0.9\n",
    "                    is_calibrated = True\n",
    "                    print(f\"[Calibration] eye_opening_avg={avg_opening:.4f}, up>{up_thresh:.4f}, down<{down_thresh:.4f}\")\n",
    "                gaze_direction = \"CENTER\"\n",
    "            else:\n",
    "                if eye_opening > up_thresh:\n",
    "                    gaze_direction = \"UP\"\n",
    "                elif eye_opening < down_thresh:\n",
    "                    gaze_direction = \"DOWN\"\n",
    "                else:\n",
    "                    gaze_direction = \"CENTER\"\n",
    "\n",
    "        gaze_text = f\"Gaze: {gaze_direction}\"\n",
    "\n",
    "        # ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "        now = time.time()\n",
    "        if gaze_direction != gaze_state:\n",
    "            if gaze_state:\n",
    "                gaze_duration_dict[gaze_state] += now - gaze_start_time\n",
    "            gaze_start_time = now\n",
    "            gaze_state = gaze_direction\n",
    "\n",
    "        # --- ÎûúÎìúÎßàÌÅ¨ ÏãúÍ∞ÅÌôî ---\n",
    "        def draw_landmark_circle(idx, color):\n",
    "            cx = int(landmarks[idx].x * w)\n",
    "            cy = int(landmarks[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 4, color, -1)\n",
    "\n",
    "        draw_landmark_circle(eye_top_id, (0, 255, 0))      # ÏúóÎààÍ∫ºÌíÄ Ï¥àÎ°ù\n",
    "        draw_landmark_circle(eye_bottom_id, (0, 0, 255))   # ÏïÑÎû´ÎààÍ∫ºÌíÄ Îπ®Í∞ï\n",
    "        draw_landmark_circle(iris_id, (255, 0, 0))         # ÎèôÍ≥µ ÌååÎûë\n",
    "\n",
    "        # --- Í≥†Í∞ú Î∞©Ìñ•(pitch) Î∂ÑÏÑù ---\n",
    "        image_points = np.array([\n",
    "            [landmarks[1].x * w, landmarks[1].y * h],\n",
    "            [landmarks[152].x * w, landmarks[152].y * h],\n",
    "            [landmarks[33].x * w, landmarks[33].y * h],\n",
    "            [landmarks[263].x * w, landmarks[263].y * h],\n",
    "            [landmarks[78].x * w, landmarks[78].y * h],\n",
    "            [landmarks[308].x * w, landmarks[308].y * h]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        camera_matrix = get_camera_matrix(w, h)\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "            pitch = np.degrees(np.arcsin(-rotation_matrix[2][1]))\n",
    "\n",
    "            if pitch < -15:\n",
    "                pitch_text = \"Head: UP\"\n",
    "            elif pitch > 5:\n",
    "                pitch_text = \"Head: DOWN\"\n",
    "            else:\n",
    "                pitch_text = \"Head: CENTER\"\n",
    "\n",
    "    # --- Í≤∞Í≥º Ï∂úÎ†• ---\n",
    "    display_text = f\"{gaze_text} | {pitch_text}\"\n",
    "    cv2.putText(frame, display_text, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    for i, (k, v) in enumerate(gaze_duration_dict.items()):\n",
    "        cv2.putText(frame, f\"{k}: {v:.1f}s\", (30, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Gaze & Head Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ÎßàÏßÄÎßâ ÏãúÏÑ† ÎàÑÏ†Å\n",
    "if gaze_state:\n",
    "    gaze_duration_dict[gaze_state] += time.time() - gaze_start_time\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nÏ¥ù ÏãúÏÑ† Ïú†ÏßÄ ÏãúÍ∞Ñ:\")\n",
    "for direction, duration in gaze_duration_dict.items():\n",
    "    print(f\"{direction}: {duration:.2f}Ï¥à\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d101c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a8830d275db2f5d56d95cb53fb469d1ca33211086217bbd3243957b61467a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
